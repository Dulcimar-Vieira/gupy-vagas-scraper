name: Scrape Gupy Jobs

on:
  schedule:
    - cron: '0 */12 * * *' # A cada 12 horas
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout do repositório
        uses: actions/checkout@v3

      - name: Instalar dependências do sistema
        run: |
          sudo apt-get update
          sudo apt-get install -y wget unzip curl xvfb libxi6 libgconf-2-4 libnss3-dev libxss1 libappindicator1 libindicator7 fonts-liberation libasound2 libatk-bridge2.0-0 libgtk-3-0

      - name: Configurar ambiente virtual
        run: |
          python -m venv venv
          source venv/bin/activate
          pip install --upgrade pip
          pip install -r requirements.txt

      - name: Instalar Google Chrome
        run: |
          wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
          sudo apt install -y ./google-chrome-stable_current_amd64.deb

      - name: Instalar ChromeDriver 135 (compatível com Chrome 135)
        run: |
          curl -Lo chromedriver https://storage.googleapis.com/chrome-for-testing-public/135.0.7049.114/linux64/chromedriver-linux64/chromedriver
          chmod +x chromedriver
          sudo mv chromedriver /usr/bin/chromedriver

          # Verificações
          google-chrome --version || true
          chromedriver --version || true

      - name: Executar o scraper
        run: |
          source venv/bin/activate
          python scraper.py
